\section{Future Work}
\label{sec:conclusion:future-work}

Based on the evaluation presented in \Cref{chap:evaluation} and the project results presented in \Cref{sec:results}, we believe that a context-aware smart home controlled using gestures is feasible in the future. 
In this section, we present functionality and design changes that would make sense to investigate, in case future work is to be done on the project.

\subsection{Continuous Recognition of Gestures}

Investigation of battery efficient approaches for continuous gesture recognition could be beneficial. The current implementation requires the user to open the Andorid Wear application, tap to start recognizing a gesture, perform the gesture and then tap again to stop the gesture recognition. From the tests we conducted with users, we found the approach to be unsuitable as starting the recognition must be done with the arm on which the watch is mounted, held in a position ready to do the gesture and stopping the gesture must be done in the position where the gesture ended.

In order to avoid this, we imagine a solution where the smartwatch continuously attempts to recognize gestures based on accelerometer data, even when the smartwatch application is in the background. Such a solution would solve the following two issues.

\begin{description}
\item[The need to open the application to perform recognition] When gesture recognition can be done with the application put into the background, \ie~not launched and visible on the screen of the smartwatch, there is no longer a need to open the application thus making it faster to control the smart home using gestures.
\item[Starting and stopping the recognition] The user no longer has to manually start and stop the gesture recognition after performing each gesture. The continuous gesture recognizer should automatically detect when the user starts performing a gesture and when he stops performing it.
\end{description}

Research in continuous gesture recognition, or \emph{real time gesture recognition} as it is referred to in~\cite{gillian2014gesture}. The authors have implemented a solution for continuous recognition using a Kinect infrared camera to detect motions and claim that it works with other sensor data as well, \eg~accelerations from an accelerometer. The article does not state an accuracy of the recognition.

\subsection{Inclusion of System State}

In the design of the Bayesian network used for context recognition presented in \Cref{sec:design:bayesian-network}, we introduced the state of the system as contextual information and as explained in \Cref{sec:implementation:status}, the functionality was not implemented. The point of introducing the state of the system, is to achieve lower belief values of actions that it does not make sense to trigger given the current state of the system. For example, an action for changing channel on the television would have a lower belief value when the television is turned off, than when it is turned on. 

When excluding the system state, the context engine may suggest such actions and since it is fair to assume that the user knows at least part of the system state, the suggested action is likely not be the intended one. By including the system state, we could potentially reduce the risk of suggesting unintended actions.

\subsection{Inclusion of User History}

Looking further into inclusion of concepts from machine intelligence could present interesting possibilities for the project. Using machine intelligence, attempts to suggest a user actions based on his historical behaviour could be made. For example, if the system detects that the user is often in a specific room at a specific time of the day, a stronger belief could be applied to that room at that time of the day. It is also a possibility to detect actions that the user is likely to trigger at certain times of the day. If the user often turns on specific lights when he gets home from work at 17:00, a stronger belief could be applied to the actions turning those lights on.

Short-term historical data, \ie~data of the users behaviour collected minutes or hours ago, could be used to further determine the context that the user is in. If he interacted with his television within that past five minutes, the belief of actions related to the television may be enhanced. This is based on the assumption that if the user recently interacted with his television, he may want to interact with it again. Further research into the behaviour of users in a smart home and their interactions with electronic devices could help confirm of dismiss this hypothesis.

\subsection{Improve Handling of Uncertainties}

In \Cref{sec:analysis:scenarios:handling_uncertainties}, we presented suggestions for handling uncertainties in the system, \eg~when a performed gesture was not recognized. In that case, we suggest presenting a list of actions for smart devices the user has recently interacted with.
The list of actions could be prioritized, \eg~ordered by how often the user triggers the action.

This functionality was not implemented in the project. Further research can investigate how we can improve handling of uncertainties.

\subsection{Investigate Alternative Designs for Context Recognition}

We have found the Bayesian network designed and implemented in this project to produce inaccurate results, especially when a gesture is associated with multiple actions, and as such future research should focus on investigating alternative designs for the context engine.

In \Cref{sec:evaluation:alternative-models} we proposed using an influence diagram rather than the Bayesian network. Further research can focus on determining whether modeling the context engine using an influence diagram would result in an accuracy exceeding 44\%. Furthermore future research could focus on determining if alternative models of the Bayesian network would produce an improved accuracy, as suggested in \Cref{sec:evaluation:alternative-models}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../master"
%%% End:
